# Pivot & Query Preparation for Metric-Space Experiments

Este mÃ³dulo genera **todos los insumos experimentales necesarios** para replicar los resultados del paper *"Indexing Metric Spaces for Exact Similarity Search"* (Chen et al.).

El objetivo es **preprocesar cada dataset** para obtener:

* **Pivotes (HFI)** â€” usados por los Ã­ndices pivot-based
* **Queries aleatorias** â€” usadas para range queries y kNN queries
* **Radios calibrados por selectividad** â€” usados para MRQ
* **Estructura unificada en JSON** â€” lista para alimentar tu benchmark



> ## Â¿QuÃ© hace este script?
> La herramienta procesa automÃ¡ticamente cada dataset real ("LA", "Words", "Color") y el dataset sintÃ©tico ("Synthetic"). Para cada dataset, genera:
>
> * pivotes seleccionados con HFI usando la mÃ©trica correcta
> * 100 queries aleatorias
> * radios calibrados para las selectividades {2%,4%,8%,16%,32%}
>
> Los archivos producidos son Ã­ndices dentro del dataset (no vectores), y se guardan en formato JSON estandarizado.
>
> Estos resultados son usados posteriormente por todos los Ã­ndices metric-space implementados en este repositorio.

---

# 1. **SelecciÃ³n de pivotes (HFI)**

Para cada dataset se ejecuta el algoritmo **Heuristic Furthest-Point Incremental (HFI)**, usando **su mÃ©trica correcta**:

| Dataset   | MÃ©trica usada |
| --------- | ------------- |
| LA        | L2-norm       |
| Words     | Edit distance |
| Color     | L1-norm       |
| Synthetic | Lâˆ-norm       |

Y se generan archivos JSON con los pivotes seleccionados para:

```
Ï€ âˆˆ {3, 5, 10, 15, 20}
```

Esto es crucial porque el paper **compara Ã­ndices pivot-based usando el mismo conjunto de pivotes HFI**.

Salida ejemplo:

```
prepared_experiment/pivots/LA_pivots_5.json
```

Contenido tÃ­pico:

```json
[1234, 98221, 55300, 11, 701991]
```

Son **Ã­ndices de objetos del dataset**, no coordenadas.

## ExplicaciÃ³n conceptual 
>En los Ã­ndices basados en pivotes, seleccionar buenos pivotes es esencial para reducir el nÃºmero de distancias. El paper utiliza HFI porque produce pivotes: muy dispersos, representativos del espacio, y con excelente poder de poda.
>
> **Â¿QuÃ© intenta lograr HFI?**
> Obtener un conjunto de pivotes que:
> - cubran el espacio lo mejor posible,
> - estÃ©n alejados entre sÃ­,
> - aumenten la eficiencia de poda.
>
> **Idea del algoritmo HFI**
> 1. El primer pivote es el primer objeto del dataset (Ã­ndice 0).
> 2. Para cada nuevo pivote:Se calcula, para cada objeto, la suma de distancias hacia los pivotes ya elegidos.
> 3. Se elige el objeto cuya suma sea mÃ¡xima.
> 4. Se repite hasta obtener Ï€ pivotes.
>    CÃ³digo conceptual:
>
>    ```python
>    suma_de_distancias(objeto, pivotes ya elegidos)
>    ```
> 
> 
> Y se elige como nuevo pivote el objeto que maximiza esa suma.
> 
> Es decir: *â€œEl siguiente pivote es el objeto que estÃ¡ globalmente mÃ¡s lejos de todos los pivotes previosâ€.*
> Se repite hasta tener Ï€ pivotes (por defecto Ï€ = 5).
> **Â¿Por quÃ© funciona bien?**
> 
> Porque la suma de distancias aproxima la diversidad del conjunto, forzando que: *los pivotes estÃ©n alejados entre sÃ­*, representen regiones distintas del espacio, permitan buenas cotas triangulares.
>
> **Â¿QuÃ© retorna HFI?**
>
> Retorna una lista de Ã­ndices dentro del dataset. No retorna coordenadas; solo posiciones.
---

# 2. **SelecciÃ³n de 100 queries aleatorias**

> SegÃºn el paper, para todas las evaluaciones: *"Each reported measurement is an average over 100 random queries. To facilitate a fair comparison, we use the same set of random queries for all indexes*
> 
> Esto garantiza: reproducibilidad, comparabilidad entre estructuras, igualdad de condiciones experimentales.
>
> ## Â¿QuÃ© representan esas 100 queries?
> 
> Son 100 objetos del dataset seleccionados al azar. Ejemplo:
>  Para cada dataset se eligen **100 objetos** que servirÃ¡n como queries para:
>
> * **Range Query (MRQ):** Para cada query, se calcula su radio segÃºn selectividad.
> * **k-Nearest Neighbors (MkNN):** Para cada query, se busca sus k-vecinos mÃ¡s cercanos.

> ## Razones por las que 100 queries son suficientes
> 1. Para estimar estadÃ­sticamente el nÃºmero de distancias, page accesses, tiempo promedio
> 2. Reduce la variancia
> 3. se usa exactamente el mismo conjunto en TODAS las pruebas
> ---
> **Por eso, guardar estas queries es indispensable.**


Salida:

```
prepared_experiment/queries/LA_queries.json
```

Ejemplo:

```json
[10023, 501991, 92311, ...]
```

Nuevamente, **son Ã­ndices del dataset**.

---

# 3. **Metric Range Queries (MRQ)**

> **CÃ¡lculo de radios para selectividades**
> El paper define los range queries en tÃ©rminos de **selectividad**:
>   ```
>       {2%, 4%, 8%, 16%, 32%}
>   ```


Para calcular el radio correspondiente a cada selectividad, se sigue el mismo procedimiento descrito en el paper:

1. Para cada una de las 100 queries, se calculan todas las distancias entre la query y cada objeto del dataset.

2. Se obtiene el percentil asociado a la selectividad (por ejemplo, el percentil 8% para selectividad 0.08).

3. Este proceso se repite para todas las queries.

4. El radio final para cada selectividad es el promedio de los 100 radios individuales.

5. Cada dataset produce un archivo JSON con los radios oficiales a utilizar en todas las ejecuciones de MRQ.

Salida:

```
prepared_experiment/radii/LA_radii.json
```

Ejemplo:

```json
{
  "0.02": 0.00091,
  "0.04": 0.00192,
  "0.08": 0.00388,
  "0.16": 0.00721,
  "0.32": 0.01344
}
```


**Estos radios deben usarse exactamente como parÃ¡metros de los MRQ para replicar la metodologÃ­a experimental del paper.**
> [!NOTE]
> **ObservaciÃ³n importante sobre los radios promedio**
>
> Al promediar los radios calculados para cada query, la cantidad exacta de resultados devueltos por un *range query* puede no coincidir exactamente con la selectividad objetivo (2%, 4%, 8%, etc.).
>
> Esto se debe a variaciones naturales en la densidad local del dataset y al hecho de que *el promedio de percentiles individuales no es igual al percentil del conjunto*.
>
> Aun asÃ­, este procedimiento:
> - replica **exactamente** la metodologÃ­a del paper,
> - produce radios consistentes para todas las estructuras,
> - garantiza comparabilidad entre Ã­ndices,
> - y modela un escenario realista donde el radio es fijo por dataset.
>
> Lo relevante en la evaluaciÃ³n es el desempeÃ±o **promedio sobre las 100 queries**, no la coincidencia exacta en cada query individual.
----

# 4. **k-Nearest Neighbor Queries (MkNNQ)**

> Los kNN queries utilizan el mismo conjunto fijo de 100 queries:  
> 1. Para cada query q, se solicita encontrar sus k vecinos mÃ¡s cercanos segÃºn la mÃ©trica del dataset.
> 2. Los valores de k evaluados, siguiendo el paper, son:
>   ```
> k âˆˆ {5, 10, 20, 50, 100}
>   ```

**Durante los experimentos: cada Ã­ndice ejecuta MkNN sobre las mismas queries y valores de k, se registran las mÃ©tricas de rendimiento (distancias, pÃ¡ginas accedidas y tiempo), los resultados se promedian sobre las 100 consultas. Esto asegura una comparaciÃ³n estandarizada entre todos los mÃ©todos.**

# Â¿Por quÃ© es necesario este preprocesamiento?

Porque el paper exige:

* pivotes comunes (HFI) para todos los Ã­ndices pivot-based
* queries fijas (si no, los resultados no son reproducibles)
* radios calibrados por selectividad, no arbitrarios
* mÃ©tricas especÃ­ficas por dataset

Con este mÃ³dulo generas **todo lo que un framework de evaluaciÃ³n** necesita antes de medir:

* `compdists`
* `page_accesses`
* `time_ms`

Y puedes alimentar fÃ¡cilmente tu benchmark.

---

# ğŸ“¦ Estructura final generada

```
prepared_experiment/
â”œâ”€â”€ pivots/
â”‚   â”œâ”€â”€ LA_pivots_3.json
â”‚   â”œâ”€â”€ LA_pivots_5.json
â”‚   â”œâ”€â”€ Words_pivots_5.json
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ queries/
â”‚   â”œâ”€â”€ LA_queries.json
â”‚   â”œâ”€â”€ Words_queries.json
â”‚
â”œâ”€â”€ radii/
â”‚   â”œâ”€â”€ LA_radii.json
â”‚   â”œâ”€â”€ Color_radii.json
â”‚   â””â”€â”€ Synthetic_radii.json
```

Todo estÃ¡ organizado por dataset y por tipo.

---

# âš™ï¸ EjecuciÃ³n automÃ¡tica

El script detecta automÃ¡ticamente si un dataset existe:

```python
DATASET_PATHS = {
    "LA": "/ruta/LA.txt",
    "Words": "/ruta/Words.txt",
    "Color": "/ruta/Color.txt",
    "Synthetic": "/ruta/Synthetic.txt"
}
```

Si un dataset no se encuentra â†’ se omite sin error.



